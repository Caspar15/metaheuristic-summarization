objectives:
  lambda_importance: 1.0
  lambda_coverage: 0.8
  lambda_redundancy: 0.7
  length_penalty: 2.0
representations:
  use: true
  method: "tfidf"  # or "sbert"
  cache: true
candidates:
  use: true
  k: 15
  mode: "hard"        # hard | soft
  sources: ["score"]  # union of: score | position | centrality
  soft_boost: 1.05
  recall_target: null
redundancy:
  method: "mmr"
  lambda: 0.7
  sim_metric: "cosine"
length_control:
  unit: "sentences"   # enforce number of sentences
  max_tokens: 100      # kept for compatibility; unused when unit=sentences
  max_sentences: 3
optimizer:
  method: "greedy"     # will be overridden via CLI per run
seed: 2024

rerank:
  enabled: false
  model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  top_n: 20
  normalize: "minmax"
  weights:
    ce: 1.0
    base: 0.0

